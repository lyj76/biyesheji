下面给你一份**“按你之前 FNN 笔记风格、但对齐那篇 JLT 论文（AR-RNN）原始写法”**的 **RNN 均衡器学习笔记**。重点是：**结构、输入/输出、公式、训练、以及为什么它比 FNN 强**，最后给你一段 **MATLAB 实现要点**（不写大段代码，写你做实验时最该记的坑点）。

---

# AR-RNN 非线性均衡器（论文原始思路）学习笔记

> 对应论文：*Feedforward and Recurrent Neural Network-Based Transfer Learning for Nonlinear Equalization in Short-Reach Optical Links*（JLT 2021）
> 论文里的 RNN 指的是 **Autoregressive RNN (AR-RNN)**，不是 LSTM/GRU，也不是“层间循环”的 L-RNN。

---

## 1. 为什么需要 RNN：FNN 的短板是什么？

在短距直检 IM/DD（PAM4 + DML）里，失真不仅是“非线性”，还有明显的**记忆效应**：

* 色散（CD）引起符号间干扰（ISI）
* 带宽限制（电/光器件频响）
* 平方律检测与线性效应混合 → “带记忆的非线性”
* 激光啁啾等

FNN 虽然能用滑窗输入把“记忆”塞进特征，但它仍是：

> **一次性映射**：( y(n)=f(x(n-L:n+L)) )

而 RNN 的想法是：

> **利用“前面符号已经被正确均衡/判决”的信息，帮助当前符号均衡**
> 也就是把“过去的输出”作为额外输入。

---

## 2. AR-RNN 的核心理念：把“过去输出”反馈回来

### 2.1 FNN 的前向传播（论文 Eq. (1)）

2 层 FNN（1 隐层 + 输出层）：

[
y = f^{[2]}!\left(W^{[2]} f^{[1]}(W^{[1]}x + b^{[1]}) + b^{[2]}\right)
]

* (x)：输入滑窗（例如 21 个输入）
* (y)：当前符号的连续幅度预测（回归）
* (f^{[1]})：隐藏层激活（论文用 tanh）
* (f^{[2]})：输出层激活（线性）

### 2.2 AR-RNN 的前向传播（论文 Eq. (2)）

AR-RNN 的区别：在隐藏层输入里加入 **输出延迟项**：

[
y = f^{[2]}!\left(
W^{[2]} f^{[1]}!\left(
\begin{bmatrix} W^{[1]} & W_d \end{bmatrix}
\begin{bmatrix} x^T \ y_d^T \end{bmatrix}

* b^{[1]}
  \right)
* b^{[2]}
  \right)
  ]

其中：

* (y_d = [y(n-1), y(n-2), \dots, y(n-k)])：**k 个输出反馈延迟**
* (W_d)：把延迟输出连到隐藏层的权重
* 论文里 **k=2**（优化后取 2 个反馈）

直观解释：

> RNN 让均衡器在估计 (y(n)) 时，同时参考：
>
> * 观测输入滑窗 (x)
> * 过去已估计的输出 (y(n-1), y(n-2))

这很像通信里的 DFE（Decision Feedback Equalizer）思路，但这里是“神经网络版本的软反馈”。

---

## 3. 结构配置（论文实验的典型设置）

论文实验里（目标系统 50Gb/s, 20km）他们用的结构大致是：

* 输入：**21 taps**（当前 + 10 前 + 10 后）
* 隐层：**12 neurons**
* 输出：**1**
* 激活：

  * hidden：tanh
  * output：linear
* feedback delays：**k=2**
* 损失：MSE（回归）

你可以把它记成一个模板：

> **AR-RNN = FNN(滑窗输入) + 输出反馈（k 个延迟）**

---

## 4. 为什么 AR-RNN 通常比 FNN 更好？

### 4.1 信息增益：输出反馈是“低 BER 的已知信息”

如果系统 BER 低（至少在训练/迭代后期），那么 (y(n-1), y(n-2)) 很接近真实符号电平。

这等于给网络额外提供了：

* “前面符号是什么”
* “前面符号经过信道后对当前符号可能造成的干扰线索”

因此 RNN 能更有效地补偿“带记忆的非线性”。

### 4.2 更接近通信均衡直觉：类似 DFE

* 传统 DFE：用过去判决来消除后游标干扰
* AR-RNN：用过去输出（软值）作为隐藏层额外输入，让 NN 学会“非线性反馈抵消”

---

## 5. 训练目标与优化

论文里用 MSE 作为损失：

[
L = \frac{1}{N}\sum_{j=1}^{N} (y_j - y_j^t)^2
]

* (y_j^t)：目标符号电平（归一化后）
* 训练算法：论文最终选择 **Levenberg–Marquardt (LM)**（对小规模回归收敛快）

> 你的实现里用 Adam 也可以，但要注意：LM/二阶方法在小网络回归上往往更快更稳。

---

## 6. 推理时 AR-RNN 怎么跑？（工程上最容易错的点）

AR-RNN 的关键是：**你必须维护延迟输出 (y_d)**。推理时有两种做法：

### 6.1 “自由运行（free-running）”

* 初始延迟输出用 0 或用训练段最后几个输出初始化
* 然后逐符号递推：

  * 用当前 (x) 和过去输出 (y_d) 预测 (y(n))
  * 更新延迟队列

优点：真实系统在线均衡就这样做
缺点：容易出现错误传播（error propagation）

### 6.2 “教师强制（teacher forcing）”（训练/仿真常用）

* 用真实符号 (y^t(n-1), y^t(n-2)) 作为反馈
* 训练更稳定
* 推理时再切换到 free-running

论文的 AR-RNN 写法更偏“通信均衡器”思路：假设在低 BER 下反馈输出可靠。

---

## 7. 迁移学习 TL 与 AR-RNN 的关系（论文的主线）

论文核心点是：**训练太慢** → 用 TL 加速。

### 7.1 无 TL 的训练（论文 Eq. (3)）

从随机权重开始优化。

### 7.2 有 TL 的训练（论文 Eq. (4)）

用源系统权重作为初始化：

* FNN：初始化 (W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]})
* RNN：还要初始化 (W_d)

直观解释：

> 源系统网络学到的“信道失真知识”是可复用的，
> 所以目标系统只需要少量样本/少量 epoch 微调即可。

---

## 8. 论文里关于 RNN 的关键结论（你最该记的“结论点”）

1. **RNN 也能迁移学习**，效果和 FNN 类似趋势
2. 最相似源系统（60Gb/s 15km）迁移效果最好
3. RNN 相对 FNN：

* 一般需要更多训练（epoch 和样本）
* 但性能可能更强（尤其复杂失真）

4. **FNN → RNN 可行**：把 (W_d=0) 则 RNN 退化为 FNN
5. **RNN → FNN 不可行**：RNN 权重是整体耦合优化的，不能简单删反馈部分

---

## 9. MATLAB 实现要点（你写代码时最常踩的坑）

### 9.1 输入与输出必须对齐（你前面已经踩过）

* 必须严格处理 offset/delay/裁边
* BER 统计只对有效索引做

### 9.2 反馈延迟的初始化非常重要

建议：

* 用训练段最后 k 个预测值初始化
* 或用真实符号（如果做 teacher forcing）

### 9.3 建议结构（和你系统风格兼容）

* 先 FFE 再 AR-RNN（最稳）
* 或把 FFE 输出作为 RNN 输入的一部分

### 9.4 损失函数

* 回归 MSE 可以
* 若 BER 很敏感：考虑 4-class 分类或 margin 加权

---

## 10. 你可以直接抄的“最简 AR-RNN 模型描述”（一段话版）

> AR-RNN 均衡器在 FNN 的滑窗输入基础上，引入 (k) 个输出延迟反馈 (y_d=[y(n-1),...,y(n-k)])，将其与输入窗一起送入隐藏层，通过额外的权重矩阵 (W_d) 学习“基于过去判决的非线性补偿”。当 BER 较低时，反馈项提供可靠的先验信息，使 AR-RNN 在补偿带记忆的非线性失真时通常优于纯 FNN。论文中设置 21 输入、12 隐层、1 输出、tanh+线性激活、k=2，并用 MSE 回归训练；配合迁移学习可显著减少训练样本和 epoch。

---

如果你愿意，我可以进一步把这份笔记升级成你更想要的形式（任选一种）：

1. **把 AR-RNN 写成“通信等效结构”**：对应到 DFE/Volterra-DFE 的直觉解释
2. **给你一版 MATLAB 的 AR-RNN 伪代码框架**：包括 teacher forcing 和 free-running 两种推理
3. **结合你当前系统参数**（2 sps、TE 同步、matched filter裁边、delay scan）写一份“不会再错位”的 RNN 数据集构造方式
