下面给你一套**可以直接写代码执行**的“算法展开（unrolling）”方案。完全按你现在的风格：MATLAB 循环、透明、参数很少、不用深度学习工具箱。

我给你两级版本：

* **版本 0（最稳、最快跑通）**：Unrolled NLMS for **FFE**（训练阶段用已知 Tx，不涉及硬判决不可导）
* **版本 1（更强，下一步）**：Unrolled NLMS + **soft decision DFE**（解决误差传播，低 ROP 更有戏）

你先做版本 0，很快就能看到是否比你 residual 更值。

---

# 目标：学出“超级自适应算法”

你不是学一个 NN，而是学 NLMS 更新里的少量“超参数”：

* 每层步长 (\mu_k)
* 每层泄露（weight decay / leakage）(\gamma_k)
* （可选）每层输入归一化稳定项 (\epsilon_k)
* （可选）门控 (g_k)（误差大时减小更新）

参数量：

* K=5 时：({\mu_k,\gamma_k}) 10 个参数（够你要的 10–50）

---

# 版本 0：Unrolled NLMS-FFE（建议你先做这个）

## 0.1 数据与符号

* 输入：接收采样（已同步、匹配滤波、抽样后得到符号速率序列）(x[n])
* 目标：已知训练序列 (a[n])（preamble 区间）

构造 FFE 输入向量（长度 (L)）：
[
\mathbf{u}[n]=[x[n],x[n-1],\dots,x[n-L+1]]^\top
]

输出：
[
y^{(k)}[n] = (\mathbf{w}^{(k)})^\top \mathbf{u}[n]
]
误差：
[
e^{(k)}[n] = a[n]-y^{(k)}[n]
]

---

## 0.2 展开 K 步 NLMS 更新（核心）

对每个样本 n，我们在内部做 K 次“虚拟更新”，形成 K 层网络：

[
\mathbf{w}^{(k+1)} =
(1-\gamma_k)\mathbf{w}^{(k)} + \mu_k \frac{e^{(k)}[n]\mathbf{u}[n]}{|\mathbf{u}[n]|^2+\epsilon}
]

* (\mu_k>0)：第 k 层步长（学习）
* (\gamma_k\in[0,1))：泄露项（学习，用来抗噪/抗漂移）
* (\epsilon)：稳定项（固定一个小常数即可，比如 (10^{-3})）

完成 K 次更新后，用 (\mathbf{w}^{(K)}) 给该符号的最终输出：
[
\hat y[n]=(\mathbf{w}^{(K)})^\top\mathbf{u}[n]
]

**注意：** 这不是在同一个样本上“更新 K 次真实算法”，而是为了把“更新过程”当成一个可学习计算图。推理时你可以：

* 仍然按 K 次更新跑（在线适配），或
* 只保留学到的一个“等效更新规则”（后面说）

---

## 0.3 训练目标（不黑盒、可手写）

先用最简单的平方误差（训练稳定，容易跑通）：

[
\mathcal{L} = \sum_{n=1}^{N_\text{pre}} \frac12 (a[n]-\hat y[n])^2
]

你要学的是 (\mu_k,\gamma_k)。

---

## 0.4 “怎么学 (\mu_k,\gamma_k)”（手写可实现的两种方案）

### 方案 A（推荐，最易落地）：坐标搜索 / SPSA / 简单梯度近似

因为参数量很小（10 个），你可以不用完整反向传播。

**A1：坐标搜索（最稳）**

* 初始化 (\mu_k,\gamma_k)
* 每次只改一个参数一点点，看 preamble loss 是否下降
* 类似“超参数学习”，但非常稳定

优点：实现最简单、不会爆。缺点：慢一点但你参数少。

**A2：SPSA（两次评估估计梯度）**
每个 epoch 做两次 loss：

* (\theta+\Delta)
* (\theta-\Delta)

用差分估计梯度更新 (\theta=[\mu_1..,\gamma_1..])

优点：参数维度小，收敛快；实现简单。缺点：有噪声，但可以平均。

> 我建议你先用 A1/A2 跑通，等你结果稳定再做精确反传。

---

### 方案 B（更“正统”，但仍然能手写）：反向传播 through unrolled updates

因为 K 小、L 小，你完全可以手写梯度（或者用数值差分）。

如果你愿意，我可以再下一条把完整的解析梯度推导给你。但你现在要“可执行”，我先给你更稳的 A 方案，让你先拿到结果。

---

## 0.5 初始化与参数约束（很重要）

为了稳定：

* 用参数化确保范围：

  * (\mu_k = \mu_{\max}\cdot \sigma(\tilde\mu_k))，(\mu_{\max}) 可取 1.5
  * (\gamma_k = \gamma_{\max}\cdot \sigma(\tilde\gamma_k))，(\gamma_{\max}) 可取 0.05
* 固定 (\epsilon=10^{-3}) 或 (10^{-4})
* K 建议 3～7，先用 5

初始化建议：

* (\mu_k) 全设成 0.5 左右（NLMS 常见稳定范围）
* (\gamma_k) 先设 0 或很小（1e-3）

---

## 0.6 推理/在线阶段怎么用（两种模式）

**模式 1：保持在线更新（推荐）**
你在 data payload 上继续用同样的 K 层更新，但这时候目标 (a[n]) 不知道：

* 用 decision-directed：
  [
  a[n]\approx Q(\hat y[n])
  ]
* 或 soft decision（版本 1 会给）

**模式 2：冻结权重（只当静态 FFE）**
训练结束后固定 (\mathbf{w}) 不更新，这就退化成普通 FIR，效果一般，但能给你个 sanity baseline。

---

# 版本 1：Unrolled NLMS + Soft-DFE（更强，低 ROP 更有用）

当你要对付低 ROP，最关键是减少 DFE 的误差传播。做法是：把反馈符号用 soft 形式。

## 1.1 软符号（PAM4）

电平 (l\in{-3,-1,1,3})（归一化也行）

给定输出 (y)，定义 soft 权重（温度 (\tau)）：
[
\pi_i = \frac{\exp(-(y-l_i)^2/\tau)}{\sum_j \exp(-(y-l_j)^2/\tau)}
]
软符号：
[
\tilde a = \sum_i \pi_i l_i
]

在 DFE 中用 (\tilde a[n-1],\tilde a[n-2]) 作为反馈输入，而不是硬判决。

---

## 1.2 展开对象：FFE+DFE 的 NLMS 更新

把输入向量扩展为：
[
\mathbf{u}[n]=[x[n],...,x[n-L+1],\tilde a[n-1],...,\tilde a[n-L_b]]^\top
]

然后完全同样的 K 层更新式：
[
\mathbf{w}^{(k+1)} =
(1-\gamma_k)\mathbf{w}^{(k)} + \mu_k \frac{e^{(k)}[n]\mathbf{u}[n]}{|\mathbf{u}[n]|^2+\epsilon}
]

训练阶段用真实 (a[n])（preamble）作为目标，推理阶段用 soft/hard 结合。

---

# 你现在具体应该怎么做（按执行顺序）

## Step A（今天就能做）：版本 0 跑通

* 固定 L=21（或你现在线性 FFE 的 tap）
* K=5
* 训练参数：(\mu_k,\gamma_k)（10 个）
* 学法：坐标搜索 或 SPSA（不用反传）
* 评价：rop3/5 + rop0/-1（重点看低 ROP）

对比基线：

* 传统 NLMS（单步固定 μ）
* 你 residual（12/16 参数）
* unrolled NLMS（10 参数）

如果 unrolled NLMS 在 rop0/-1 明显更稳/更低 BER，你就赢了。

---

## Step B：加门控（再加 2–3 个参数，收益常很大）

门控让更新在噪声大时更保守：

[
g^{(k)}[n]=\sigma(a_k|e^{(k)}[n]|+b_k)
]
更新改成：
[
\mathbf{w}^{(k+1)} =
(1-\gamma_k)\mathbf{w}^{(k)} + g^{(k)}[n]\mu_k \frac{e^{(k)}[n]\mathbf{u}[n]}{|\mathbf{u}[n]|^2+\epsilon}
]

这会显著提升低 SNR 的稳定性，参数仍很少。

---

## Step C：上版本 1（Soft-DFE）

当版本 0 有收益后，低 ROP 最可能继续提升的是 Soft-DFE。

---

# 你可以直接照抄的 MATLAB 伪代码骨架（版本 0）

（不涉及工具箱）

```matlab
function [y_hat, w_final, params] = unrolled_nlms_ffe(x, a, L, K, params, Npre)
% params.mu(1:K), params.gamma(1:K), params.eps

w = zeros(L,1);
eps0 = params.eps;

for n = L:Npre
    u = x(n:-1:n-L+1);
    u_norm = (u'*u) + eps0;

    % unrolled updates
    w_k = w;
    for k = 1:K
        yk = w_k.' * u;
        ek = a(n) - yk;
        w_k = (1-params.gamma(k))*w_k + params.mu(k) * (ek/u_norm) * u;
    end

    % commit update
    w = w_k;

    % output (use final w_k)
    y_hat(n) = w.' * u;
end

w_final = w;
end
```

训练（坐标搜索/SPSA）就是在外层 loop 调 params.mu/gamma，让 preamble BER 或 loss 最小。

---

# 我需要你给我 3 个数，我就能把“默认参数+训练流程”定得很稳

你回我这三项（随便估也行）：

1. 你线性 FFE 通常用的 tap 长度 L（11/21/41？）
2. 你 preamble 长度（你现在 NumPreamble_TDE=30000 对吗）
3. 你主要想优化的点是 rop0/-1 还是 rop3/5（我猜是前者）

然后我下一条直接给你：

* 一套能直接跑的 **SPSA 训练脚本模板**
* 推荐的 (\mu_{\max}, \gamma_{\max}, K)
* 以及如何在 decision-directed 阶段避免发散（很关键）
